{
  "nbformat": 4,
  "nbformat_minor": 2,
  "metadata": {
    "kernelspec": {
      "name": "synapse_pyspark",
      "display_name": "Synapse PySpark"
    },
    "language_info": {
      "name": "python"
    },
    "description": "generating interactions data - simulating data from Outlook",
    "save_output": true,
    "synapse_widget": {
      "version": "0.1",
      "state": {}
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "SparkPool1",
              "session_id": "0",
              "statement_id": 8,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2022-09-06T13:53:32.1682127Z",
              "session_start_time": null,
              "execution_start_time": "2022-09-06T13:53:32.6251769Z",
              "execution_finish_time": "2022-09-06T13:54:33.6787722Z",
              "spark_jobs": null
            },
            "text/plain": "StatementMeta(SparkPool1, 0, 8, Finished, Available)"
          },
          "metadata": {}
        }
      ],
      "metadata": {
        "microsoft": {
          "language": "python"
        }
      },
      "source": [
        "%%pyspark\r\n",
        "# Generating interactions\r\n",
        "\r\n",
        "from pyspark.sql.functions import *\r\n",
        "from pyspark.sql import types\r\n",
        "from random import randrange\r\n",
        "import datetime\r\n",
        "\r\n",
        "timestamp_udf = udf(lambda x: datetime.datetime.now() + datetime.timedelta(days = -int(x), hours = -int(x), minutes = -int(x)), types.TimestampType())\r\n",
        "df1 = spark.sql(\"select id as person_id from dataverse_contosodefau_unq35c64bd569f74356a67a71fce467b.account limit 1000\") #random 1000 users\r\n",
        "\r\n",
        "#100 -> 100(2^i)\r\n",
        "for _ in range(5):\r\n",
        "    df1 = df1.union(df1).sample(False, 0.6).coalesce(10)\r\n",
        "df1 = df1.orderBy(rand()) #shuffled\r\n",
        "\r\n",
        "#generate a random timestamp\r\n",
        "df1 = df1.withColumn(\"offset\", round(rand()*100,0))\r\n",
        "df1 = df1.withColumn(\"interaction_date\", timestamp_udf(df1['offset']))\r\n",
        "#df1.createOrReplaceGlobalTempView(\"interactions\")\r\n",
        "df1.sample(False, 0.8).select(\"person_id\", \"interaction_date\").coalesce(10).write.parquet(\"interactions\", mode = 'overwrite')"
      ]
    }
  ]
}